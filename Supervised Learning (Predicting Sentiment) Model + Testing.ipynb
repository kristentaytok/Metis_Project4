{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T20:32:41.271195Z",
     "start_time": "2019-11-14T20:32:39.330642Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "\n",
    "#Vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Dimensionality Reduction\n",
    "from sklearn.decomposition import TruncatedSVD #LSA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from gensim import corpora, models, similarities, matutils #LDA\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Bayes Optimization Parameter Tuner\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For Handling Imbalanced Data for Classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import numpy as np\n",
    "\n",
    "#For Classification\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize  #not needed b/c filtered out neutral ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T20:32:41.662568Z",
     "start_time": "2019-11-14T20:32:41.306538Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_pickle('full_df_preprocessed.pkl')\n",
    "#change sentiment to numbers as classifiers \n",
    "full_df['sentiment'].replace('positive',1,inplace=True)\n",
    "full_df['sentiment'].replace('negative',0,inplace=True)\n",
    "full_df = full_df[(full_df.sentiment != 'neutral')]\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_df.drop(['rating','review_text','movie','review_site','review_text','sentiment', 'review_tokens'], axis=1), full_df['sentiment'], test_size=0.2, random_state=41)\n",
    "\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Number of Topics\n",
    "***IMPORTANT To vectorize, reduce dimensions separately for train and test (or subtrain and valid), and normalize [for length] and standardscale [for ]. Standardscaler FITTING should ONLY BE DONE ON TRAIN, fitted Standardscaler should be used to TRANSFORM TRAIN and TEST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:04:24.598387Z",
     "start_time": "2019-11-14T23:04:15.288217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7123270016344335\n",
      "0.7046903617216118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.52955193,  0.52313825,  0.48850258,  0.09008075]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subtrain, X_valid, y_subtrain, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=41)\n",
    "\n",
    "###SUBTRAIN\n",
    "subtrain_corpus = X_subtrain.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "\n",
    "TFIDF_vec = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king'])\n",
    "TFIDF_subtrain_tuning = TFIDF_vec.fit_transform(subtrain_corpus)\n",
    "NMF_model = NMF(n_components=4,random_state=10)\n",
    "TFIDF_NMF_subtrain_tuning = NMF_model.fit_transform(TFIDF_subtrain_tuning)\n",
    "\n",
    "X_subtrain_TFIDF_NMF_normalized_tuning= normalize(TFIDF_NMF_subtrain_tuning)\n",
    "X_subtrain_TFIDF_NMF_tuning = pd.DataFrame(X_subtrain_TFIDF_NMF_normalized_tuning,columns=['topic1','topic2','topic3','topic4'])\n",
    "#,'topic5','topic6','topic7','topic8','topic9','topic10','topic11'\n",
    "ss = StandardScaler()\n",
    "scaled_subtrain_TFIDF_NMF_tuning = ss.fit_transform(X_subtrain_TFIDF_NMF_tuning)\n",
    "\n",
    "\n",
    "\n",
    "###VALID\n",
    "\n",
    "valid_corpus = X_valid.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "TFIDF_valid = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king']).fit_transform(valid_corpus)\n",
    "TFIDF_NMF_valid = NMF(n_components=4,random_state=10).fit_transform(TFIDF_valid)\n",
    "\n",
    "X_valid_TFIDF_NMF_normalized = normalize(TFIDF_NMF_valid)\n",
    "scaled_valid_TFIDF_NMF_tuning = ss.transform(X_valid_TFIDF_NMF_normalized)\n",
    "\n",
    "logreg_classwt_NMF_tuning = LogisticRegression(C=0.001, penalty='l2', solver='saga', class_weight='balanced', random_state=41, max_iter=500).fit(scaled_subtrain_TFIDF_NMF_tuning, y_subtrain)\n",
    "y_pred_classwt_NMF_subtrain_tuning = logreg_classwt_NMF_tuning.predict(scaled_subtrain_TFIDF_NMF_tuning)\n",
    "y_pred_classwt_NMF_valid_tuning = logreg_classwt_NMF_tuning.predict(scaled_valid_TFIDF_NMF_tuning)\n",
    "\n",
    "print(roc_auc_score(y_subtrain, y_pred_classwt_NMF_subtrain_tuning))\n",
    "print(roc_auc_score(y_valid, y_pred_classwt_NMF_valid_tuning))\n",
    "logreg_classwt_NMF_tuning.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:22:36.513168Z",
     "start_time": "2019-11-14T22:19:47.333102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:49<00:00,  2.96it/s, best loss: 0.22456912767289272]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.22456912767289272,\n",
       " 'params': {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {'C': hp.choice('C', [0.001,0.05, 0.01,0.1,0.5,1,5, 10,50,100,500,1000,5000, 10000]),\n",
    "        'solver': hp.choice('solver', ['saga', 'liblinear']),\n",
    "        'penalty': hp.choice('penalty', ['l1','l2'])}\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Logistic Regerssion Machine Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    \n",
    "    model = LogisticRegression(**params, class_weight='balanced', random_state=41, verbose=0,max_iter=500)\n",
    "    \n",
    "    best_score = cross_val_score(model, scaled_subtrain_TFIDF_NMF_tuning, y_subtrain, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "MAX_EVALS = 500\n",
    "trials = Trials()\n",
    "# We initialize trials object here to be able to see our results after algorithm is complete\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = MAX_EVALS,\n",
    "            trials= trials)\n",
    "best\n",
    "\n",
    "# To see which results were best\n",
    "best_results = sorted(trials.results, key = lambda x: x['loss'])\n",
    "best_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:03:52.093080Z",
     "start_time": "2019-11-14T22:03:52.087017Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix+1)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:05:07.908775Z",
     "start_time": "2019-11-14T23:05:07.902741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "not, original, like, well, make, story, remake, feel, character, new, song, version, time, animate, amaze, voice, scene, lion, look, classic, little, no, animal, only, enjoy, cgi, loved, way, beautiful, cast, aladdin, real, act, actor, old, music, genie, kid, fun, smith, awesome, good, great, love\n",
      "\n",
      "Topic  2\n",
      "love, amaze, kid, smith, awesome, beautiful, old, music, song, genie, story, aladdin, lion, new, time, version, real, make, little, character, animal, fun, way, actor, cast, enjoy, animate, look, well, loved, only, feel, classic, scene, good, great, like, cgi, no, not, original, remake, voice, act\n",
      "\n",
      "Topic  3\n",
      "great, smith, loved, genie, music, cast, story, fun, awesome, classic, amaze, kid, enjoy, remake, aladdin, act, actor, song, new, beautiful, make, old, little, cgi, time, voice, version, character, animate, way, real, original, well, scene, animal, like, only, not, feel, no, love, good, look, lion\n",
      "\n",
      "Topic  4\n",
      "good, smith, genie, enjoy, music, make, aladdin, act, fun, cast, actor, version, story, kid, little, song, animate, cgi, awesome, character, classic, scene, time, old, feel, voice, amaze, beautiful, only, remake, look, no, way, well, animal, real, new, original, great, like, lion, love, loved, not\n"
     ]
    }
   ],
   "source": [
    "display_topics(NMF_model, TFIDF_vec.get_feature_names(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[-0.60224648,  0.68573341,  0.45763012,  0.18590289,  0.68605954,\n",
    "        -0.28091036, -0.16709458,  0.18078187, -0.19779586,  0.31671876,\n",
    "        -0.12705248]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:01:53.546140Z",
     "start_time": "2019-11-14T21:01:53.543342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28541, 56)\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF_subtrain_tuning.shape)\n",
    "\n",
    "#how to interp, significance of results\n",
    "#came up with other questions --> next steps to push forward\n",
    "\n",
    "#doc = just 'cgi--> normlaize, standardize, test steps (as a doc)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:15:15.371600Z",
     "start_time": "2019-11-14T22:15:15.366075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act',\n",
       " 'actor',\n",
       " 'aladdin',\n",
       " 'amaze',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'awesome',\n",
       " 'beautiful',\n",
       " 'cast',\n",
       " 'cgi',\n",
       " 'character',\n",
       " 'classic',\n",
       " 'enjoy',\n",
       " 'feel',\n",
       " 'fun',\n",
       " 'genie',\n",
       " 'good',\n",
       " 'great',\n",
       " 'kid',\n",
       " 'king',\n",
       " 'like',\n",
       " 'lion',\n",
       " 'little',\n",
       " 'look',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'make',\n",
       " 'music',\n",
       " 'new',\n",
       " 'no',\n",
       " 'not',\n",
       " 'old',\n",
       " 'only',\n",
       " 'original',\n",
       " 'real',\n",
       " 'remake',\n",
       " 'scene',\n",
       " 'smith',\n",
       " 'song',\n",
       " 'story',\n",
       " 'time',\n",
       " 'version',\n",
       " 'voice',\n",
       " 'way',\n",
       " 'well']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:29:41.041962Z",
     "start_time": "2019-11-14T22:29:41.012485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_subtrain['topic'] = X_subtrain_TFIDF_NMF_tuning.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:44:32.442528Z",
     "start_time": "2019-11-14T21:44:32.438881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1639     1\n",
       "3322     1\n",
       "10389    0\n",
       "6261     1\n",
       "1766     1\n",
       "        ..\n",
       "5833     1\n",
       "5494     1\n",
       "518      1\n",
       "2753     1\n",
       "14786    1\n",
       "Name: sentiment, Length: 28541, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_subtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:29:51.781990Z",
     "start_time": "2019-11-14T22:29:51.774241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_processed</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1639</td>\n",
       "      <td>amazing movie no complaint round applause</td>\n",
       "      <td>topic4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3322</td>\n",
       "      <td>love took childhood</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10389</td>\n",
       "      <td>adds little previous version cinematography bl...</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6261</td>\n",
       "      <td>excellent love new song plus original song gen...</td>\n",
       "      <td>topic2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1766</td>\n",
       "      <td>not bad live action disney movie come life not...</td>\n",
       "      <td>topic4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5833</td>\n",
       "      <td>think movie great action digital effect real r...</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5494</td>\n",
       "      <td>movie great</td>\n",
       "      <td>topic3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>prince ali fabulous ali ababwa song stick head...</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2753</td>\n",
       "      <td>loved movie</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14786</td>\n",
       "      <td>not disappoint huge fan original loved 3d rema...</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28541 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_processed   topic\n",
       "1639           amazing movie no complaint round applause  topic4\n",
       "3322                                 love took childhood  topic1\n",
       "10389  adds little previous version cinematography bl...  topic1\n",
       "6261   excellent love new song plus original song gen...  topic2\n",
       "1766   not bad live action disney movie come life not...  topic4\n",
       "...                                                  ...     ...\n",
       "5833   think movie great action digital effect real r...  topic1\n",
       "5494                                         movie great  topic3\n",
       "518    prince ali fabulous ali ababwa song stick head...  topic1\n",
       "2753                                         loved movie  topic1\n",
       "14786  not disappoint huge fan original loved 3d rema...  topic1\n",
       "\n",
       "[28541 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T22:42:07.980329Z",
     "start_time": "2019-11-14T22:42:07.914997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>disney clear time favorite movie not stress en...</td>\n",
       "      <td>topic1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>disney clear time favorite movie not stress en...</td>\n",
       "      <td>topic1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>perfect blend spectacle music</td>\n",
       "      <td>topic1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>perfect blend spectacle music</td>\n",
       "      <td>topic1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hate change line original feel wrong level</td>\n",
       "      <td>topic1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20145</td>\n",
       "      <td>life lesson not want</td>\n",
       "      <td>topic4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20146</td>\n",
       "      <td>grow watch lion king amaze amaze people movie ...</td>\n",
       "      <td>topic2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20147</td>\n",
       "      <td>far easy</td>\n",
       "      <td>topic1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20148</td>\n",
       "      <td>definitely not nearly superior original origin...</td>\n",
       "      <td>topic3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20149</td>\n",
       "      <td>character taxidermied animal dreadfully lifele...</td>\n",
       "      <td>topic2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35048 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_processed   topic  sentiment\n",
       "0      disney clear time favorite movie not stress en...  topic1          0\n",
       "0      disney clear time favorite movie not stress en...  topic1          1\n",
       "0                          perfect blend spectacle music  topic1          0\n",
       "0                          perfect blend spectacle music  topic1          1\n",
       "0             hate change line original feel wrong level  topic1          0\n",
       "...                                                  ...     ...        ...\n",
       "20145                               life lesson not want  topic4          1\n",
       "20146  grow watch lion king amaze amaze people movie ...  topic2          1\n",
       "20147                                           far easy  topic1          1\n",
       "20148  definitely not nearly superior original origin...  topic3          1\n",
       "20149  character taxidermied animal dreadfully lifele...  topic2          0\n",
       "\n",
       "[35048 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:44:26.884749Z",
     "start_time": "2019-11-15T13:44:13.599526Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7136753413766308\n",
      "0.7178528874345186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.53965851,  0.54692323,  0.50071603,  0.09383977]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TRAIN\n",
    "train_corpus = X_train.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "\n",
    "TFIDF_vec_final = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king'])\n",
    "TFIDF_train = TFIDF_vec_final.fit_transform(train_corpus)\n",
    "NMF_model_final = NMF(n_components=4,random_state=10)\n",
    "TFIDF_NMF_train = NMF_model_final.fit_transform(TFIDF_train)\n",
    "\n",
    "X_train_TFIDF_NMF_normalized = normalize(TFIDF_NMF_train)\n",
    "X_train_TFIDF_NMF = pd.DataFrame(X_train_TFIDF_NMF_normalized,columns=['topic1','topic2','topic3','topic4'])\n",
    "#,'topic5','topic6','topic7','topic8','topic9','topic10','topic11'\n",
    "ss = StandardScaler()\n",
    "scaled_train_TFIDF_NMF = ss.fit_transform(X_train_TFIDF_NMF)\n",
    "\n",
    "\n",
    "\n",
    "###TEST\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "test_corpus = X_test.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "TFIDF_test = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king']).fit_transform(test_corpus)\n",
    "TFIDF_NMF_test = NMF(n_components=4,random_state=10).fit_transform(TFIDF_test)\n",
    "\n",
    "X_test_TFIDF_NMF_normalized = normalize(TFIDF_NMF_test)\n",
    "scaled_test_TFIDF_NMF = ss.transform(X_test_TFIDF_NMF_normalized)\n",
    "\n",
    "logreg_classwt_NMF_test = LogisticRegression(C=0.001, penalty='l2', solver='saga', class_weight='balanced', random_state=41, max_iter=500)\n",
    "logreg_classwt_NMF_test.fit(scaled_train_TFIDF_NMF, y_train)\n",
    "y_pred_classwt_NMF_train = logreg_classwt_NMF_test.predict(scaled_train_TFIDF_NMF)\n",
    "y_pred_classwt_NMF_test = logreg_classwt_NMF_test.predict(scaled_test_TFIDF_NMF)\n",
    "\n",
    "print(roc_auc_score(y_train, y_pred_classwt_NMF_train))\n",
    "print(roc_auc_score(y_test, y_pred_classwt_NMF_test))\n",
    "logreg_classwt_NMF_test.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:55:03.691831Z",
     "start_time": "2019-11-14T23:55:03.685354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "not, original, like, well, make, remake, story, feel, character, new, version, song, time, animate, voice, amaze, scene, look, lion, classic, no, little, animal, only, enjoy, cgi, way, cast, beautiful, real\n",
      "\n",
      "Topic  2\n",
      "love, amaze, kid, smith, awesome, beautiful, old, music, song, genie, story, lion, aladdin, time, new, version, make, real, character, animal, little, fun, actor, loved, way, cast, enjoy, animate, look, well\n",
      "\n",
      "Topic  3\n",
      "great, smith, loved, genie, music, cast, story, fun, awesome, amaze, classic, kid, enjoy, remake, aladdin, act, actor, song, make, new, beautiful, little, old, character, voice, time, cgi, animate, version, well\n",
      "\n",
      "Topic  4\n",
      "good, smith, genie, enjoy, music, aladdin, make, act, story, fun, actor, cast, version, kid, song, little, animate, awesome, cgi, character, classic, old, amaze, scene, feel, time, only, voice, beautiful, look\n"
     ]
    }
   ],
   "source": [
    "display_topics(NMF_model_final, TFIDF_vec_final.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:09:14.442289Z",
     "start_time": "2019-11-14T23:09:14.438110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8255     1\n",
       "4326     1\n",
       "12260    1\n",
       "16543    1\n",
       "896      1\n",
       "        ..\n",
       "1109     1\n",
       "683      0\n",
       "10723    1\n",
       "17324    0\n",
       "2488     1\n",
       "Name: sentiment, Length: 8920, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:21:54.456466Z",
     "start_time": "2019-11-14T23:21:54.444398Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test['topic'] = pd.DataFrame(scaled_test_TFIDF_NMF,columns=['topic1','topic2','topic3','topic4']).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:21:56.604873Z",
     "start_time": "2019-11-14T23:21:56.599535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_processed       0\n",
       "topic               3661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:22:00.062150Z",
     "start_time": "2019-11-14T23:22:00.026926Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train['topic'] = X_train_TFIDF_NMF.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:22:01.792173Z",
     "start_time": "2019-11-14T23:22:01.783177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_processed    0\n",
       "topic               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:22:03.494806Z",
     "start_time": "2019-11-14T23:22:03.228640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_test.to_csv('X_test_final.csv')\n",
    "y_test.to_csv('y_test_final.csv')\n",
    "X_train.to_csv('X_train_final.csv')\n",
    "y_train.to_csv('y_train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:31:16.838881Z",
     "start_time": "2019-11-14T23:31:16.129355Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.to_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:35:14.755133Z",
     "start_time": "2019-11-14T23:35:14.740291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>movie</th>\n",
       "      <th>review_site</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Disney, WHAT. HAVE. YOU. DONE Just to be clea...</td>\n",
       "      <td>lionking</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[disney, clear, time, favorite, movie, not, st...</td>\n",
       "      <td>disney clear time favorite movie not stress en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No soul. The original Lion King is one of my ...</td>\n",
       "      <td>lionking</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[no, soul, original, lion, king, favorite, mov...</td>\n",
       "      <td>no soul original lion king favorite movie time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Seriously? So anyone else notice it has a hig...</td>\n",
       "      <td>lionking</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[seriously, notice, high, score, 7.5, rating, ...</td>\n",
       "      <td>seriously notice high score 7.5 rating not str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Overrated and way too much spotlight on beyon...</td>\n",
       "      <td>lionking</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[overrated, way, spotlight, beyonce, lion, kin...</td>\n",
       "      <td>overrated way spotlight beyonce lion king only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Terrible acting!! Doesn't compare to the orig...</td>\n",
       "      <td>lionking</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[terrible, act, not, compare, original, love, ...</td>\n",
       "      <td>terrible act not compare original love origina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>A magically wonderful film filled with adventu...</td>\n",
       "      <td>cinderella</td>\n",
       "      <td>rottentomatoes</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[magically, wonderful, film, fill, adventure, ...</td>\n",
       "      <td>magically wonderful film fill adventure fantas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3041</td>\n",
       "      <td>Disney has overdid the faithfulness of their o...</td>\n",
       "      <td>cinderella</td>\n",
       "      <td>rottentomatoes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[disney, overdo, faithfulness, animate, classi...</td>\n",
       "      <td>disney overdo faithfulness animate classic pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3042</td>\n",
       "      <td>Magic....that's about right. A re-tell of the ...</td>\n",
       "      <td>cinderella</td>\n",
       "      <td>rottentomatoes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[magic, ...., right, tell, original, disney, m...</td>\n",
       "      <td>magic .... right tell original disney movie li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3043</td>\n",
       "      <td>A good movie that sets it apart from the origi...</td>\n",
       "      <td>cinderella</td>\n",
       "      <td>rottentomatoes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, movie, set, apart, original, story, cin...</td>\n",
       "      <td>good movie set apart original story cinderella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3044</td>\n",
       "      <td>It's the Cinderella you know but it's really d...</td>\n",
       "      <td>cinderella</td>\n",
       "      <td>rottentomatoes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[cinderella, know, delightfully, charm]</td>\n",
       "      <td>cinderella know delightfully charm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44597 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text       movie  \\\n",
       "0      Disney, WHAT. HAVE. YOU. DONE Just to be clea...    lionking   \n",
       "1      No soul. The original Lion King is one of my ...    lionking   \n",
       "5      Seriously? So anyone else notice it has a hig...    lionking   \n",
       "6      Overrated and way too much spotlight on beyon...    lionking   \n",
       "8      Terrible acting!! Doesn't compare to the orig...    lionking   \n",
       "...                                                 ...         ...   \n",
       "3040  A magically wonderful film filled with adventu...  cinderella   \n",
       "3041  Disney has overdid the faithfulness of their o...  cinderella   \n",
       "3042  Magic....that's about right. A re-tell of the ...  cinderella   \n",
       "3043  A good movie that sets it apart from the origi...  cinderella   \n",
       "3044  It's the Cinderella you know but it's really d...  cinderella   \n",
       "\n",
       "         review_site  rating sentiment  \\\n",
       "0               imdb       1         0   \n",
       "1               imdb       1         0   \n",
       "5               imdb       1         0   \n",
       "6               imdb       1         0   \n",
       "8               imdb       1         0   \n",
       "...              ...     ...       ...   \n",
       "3040  rottentomatoes       5         1   \n",
       "3041  rottentomatoes       4         1   \n",
       "3042  rottentomatoes       4         1   \n",
       "3043  rottentomatoes       4         1   \n",
       "3044  rottentomatoes       4         1   \n",
       "\n",
       "                                          review_tokens  \\\n",
       "0     [disney, clear, time, favorite, movie, not, st...   \n",
       "1     [no, soul, original, lion, king, favorite, mov...   \n",
       "5     [seriously, notice, high, score, 7.5, rating, ...   \n",
       "6     [overrated, way, spotlight, beyonce, lion, kin...   \n",
       "8     [terrible, act, not, compare, original, love, ...   \n",
       "...                                                 ...   \n",
       "3040  [magically, wonderful, film, fill, adventure, ...   \n",
       "3041  [disney, overdo, faithfulness, animate, classi...   \n",
       "3042  [magic, ...., right, tell, original, disney, m...   \n",
       "3043  [good, movie, set, apart, original, story, cin...   \n",
       "3044            [cinderella, know, delightfully, charm]   \n",
       "\n",
       "                                       review_processed  \n",
       "0     disney clear time favorite movie not stress en...  \n",
       "1     no soul original lion king favorite movie time...  \n",
       "5     seriously notice high score 7.5 rating not str...  \n",
       "6     overrated way spotlight beyonce lion king only...  \n",
       "8     terrible act not compare original love origina...  \n",
       "...                                                 ...  \n",
       "3040  magically wonderful film fill adventure fantas...  \n",
       "3041  disney overdo faithfulness animate classic pro...  \n",
       "3042  magic .... right tell original disney movie li...  \n",
       "3043  good movie set apart original story cinderella...  \n",
       "3044                 cinderella know delightfully charm  \n",
       "\n",
       "[44597 rows x 7 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:37:13.110481Z",
     "start_time": "2019-11-14T23:37:13.104646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30928\n",
       "0     4749\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T23:36:50.049165Z",
     "start_time": "2019-11-14T23:36:50.042614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_processed</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8255</td>\n",
       "      <td>loved boy enjoy</td>\n",
       "      <td>topic3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4326</td>\n",
       "      <td>movie great voice great cgi good not perfect</td>\n",
       "      <td>topic2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12260</td>\n",
       "      <td>truly enjoy version lion king</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16543</td>\n",
       "      <td>movie especially og 90s enjoy not compare cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>impress movie not technical aspect good execut...</td>\n",
       "      <td>topic4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1109</td>\n",
       "      <td>special film level</td>\n",
       "      <td>topic2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>pretty like wrong movie</td>\n",
       "      <td>topic2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10723</td>\n",
       "      <td>absolutely love lion king</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17324</td>\n",
       "      <td>smith great effect great act okay not apprecia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2488</td>\n",
       "      <td>family enjoy movie love loungers</td>\n",
       "      <td>topic1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_processed   topic\n",
       "8255                                     loved boy enjoy  topic3\n",
       "4326        movie great voice great cgi good not perfect  topic2\n",
       "12260                      truly enjoy version lion king     NaN\n",
       "16543  movie especially og 90s enjoy not compare cont...     NaN\n",
       "896    impress movie not technical aspect good execut...  topic4\n",
       "...                                                  ...     ...\n",
       "1109                                  special film level  topic2\n",
       "683                              pretty like wrong movie  topic2\n",
       "10723                          absolutely love lion king     NaN\n",
       "17324  smith great effect great act okay not apprecia...     NaN\n",
       "2488                    family enjoy movie love loungers  topic1\n",
       "\n",
       "[8920 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:45:27.778310Z",
     "start_time": "2019-11-15T13:45:27.613234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/mglearn/plot_pca.py:7: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='cache'\", use \"location='cache'\" instead.\n",
      "  memory = Memory(cachedir=\"cache\")\n",
      "/Users/kristentokunaga/anaconda3/envs/metis/lib/python3.7/site-packages/mglearn/plot_nmf.py:7: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='cache'\", use \"location='cache'\" instead.\n",
      "  memory = Memory(cachedir=\"cache\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:50:58.833303Z",
     "start_time": "2019-11-15T13:50:58.814692Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of coefficients 4 doesn't match number offeature names 44.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-b03be7473eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmglearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_coefficients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg_classwt_NMF_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFIDF_vec_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_top_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/mglearn/tools.py\u001b[0m in \u001b[0;36mvisualize_coefficients\u001b[0;34m(coefficients, feature_names, n_top_features)\u001b[0m\n\u001b[1;32m     34\u001b[0m         raise ValueError(\"Number of coefficients {} doesn't match number of\"\n\u001b[1;32m     35\u001b[0m                          \"feature names {}.\".format(len(coefficients),\n\u001b[0;32m---> 36\u001b[0;31m                                                     len(feature_names)))\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# get coefficients with large absolute values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of coefficients 4 doesn't match number offeature names 44."
     ]
    }
   ],
   "source": [
    "\n",
    "mglearn.tools.visualize_coefficients(logreg_classwt_NMF_test.coef_, TFIDF_vec_final.get_feature_names(), n_top_features=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model with \"New\" (One-word) Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T05:56:34.272420Z",
     "start_time": "2019-11-15T05:56:34.270037Z"
    }
   },
   "outputs": [],
   "source": [
    "word_test_review = ['regular']\n",
    "word_test = pd.DataFrame(word_test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T05:56:34.479887Z",
     "start_time": "2019-11-15T05:56:34.467803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0.7178528874345186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.53965851,  0.54692323,  0.50071603,  0.09383977]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "###TEST\n",
    "\n",
    "\n",
    "word_corpus = word_test.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "TFIDF_word = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king']).fit_transform(word_corpus)\n",
    "TFIDF_NMF_word = NMF(n_components=4,random_state=10).fit_transform(TFIDF_word)\n",
    "\n",
    "word_TFIDF_NMF_normalized = normalize(TFIDF_NMF_word)\n",
    "scaled_word_TFIDF_NMF = ss.transform(word_TFIDF_NMF_normalized)\n",
    "\n",
    "y_pred_classwt_NMF_word = logreg_classwt_NMF_test.predict(scaled_word_TFIDF_NMF)\n",
    "\n",
    "print(y_pred_classwt_NMF_word)\n",
    "print(roc_auc_score(y_test, y_pred_classwt_NMF_test))\n",
    "logreg_classwt_NMF_test.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRAIN\n",
    "train_corpus = X_train.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "\n",
    "TFIDF_vec_final = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film','live','action','watch','think','go','job','disney','king'])\n",
    "TFIDF_train = TFIDF_vec_final.fit_transform(train_corpus)\n",
    "NMF_model_final = NMF(n_components=4,random_state=10)\n",
    "TFIDF_NMF_train = NMF_model_final.fit_transform(TFIDF_train)\n",
    "\n",
    "X_train_TFIDF_NMF_normalized = normalize(TFIDF_NMF_train)\n",
    "X_train_TFIDF_NMF = pd.DataFrame(X_train_TFIDF_NMF_normalized,columns=['topic1','topic2','topic3','topic4'])\n",
    "#,'topic5','topic6','topic7','topic8','topic9','topic10','topic11'\n",
    "ss = StandardScaler()\n",
    "scaled_train_TFIDF_NMF = ss.fit_transform(X_train_TFIDF_NMF)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-trying ROS (without Class Weight = Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:17:27.781812Z",
     "start_time": "2019-11-15T13:17:13.899883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7009680816591057\n",
      "0.6867416437728938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.60199631, -0.0007947 ,  0.4024587 ,  0.53056368, -0.35693496]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subtrain, X_valid, y_subtrain, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=41)\n",
    "\n",
    "\n",
    "# #SUBTRAIN\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "X_ros_resampled_subtrain, y_ros_resampled_subtrain = ros.fit_sample(X_subtrain,y_subtrain)\n",
    "ros_corpus = pd.DataFrame(X_ros_resampled_subtrain).iloc[:,0].tolist() #convert from dataframe to series, to transform into list of reviews\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), min_df=0.05)\n",
    "tfidf_doc_words = tfidf_vec.fit_transform(ros_corpus)\n",
    "NMF_topics = NMF(n_components=5,random_state=10)\n",
    "TFIDF_NMF_ros = NMF_topics.fit_transform(tfidf_doc_words)\n",
    "#Need to normalize before classifying to predict positive vs. negative sentiment\n",
    "X_subtrain_TFIDF_NMF_ros_normalized = normalize(TFIDF_NMF_ros)\n",
    "\n",
    "X_TFIDF_NMF_ros_resampled_subtrain = pd.DataFrame(X_subtrain_TFIDF_NMF_ros_normalized, columns = ['topic1', 'topic2', 'topic3', 'topic4', 'topic5'])\n",
    "y_TFIDF_NMF_ros_resampled_subtrain = pd.DataFrame(y_ros_resampled_subtrain, columns = ['sentiment'])\n",
    "\n",
    "ss= StandardScaler()\n",
    "scaled_X_subtrain_TFIDF_NMF_ros = ss.fit_transform(X_TFIDF_NMF_ros_resampled_subtrain)\n",
    "\n",
    "\n",
    "###VALID\n",
    "\n",
    "valid_corpus = X_valid.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "Pipeline_TFIDF_NMF_valid = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,5), min_df=0.05)),\n",
    "                ('NMF', NMF(n_components=5,random_state=10))])\n",
    "TFIDF_NMF_valid = Pipeline_TFIDF_NMF_valid.fit_transform(valid_corpus)\n",
    "\n",
    "X_valid_TFIDF_NMF_normalized = normalize(TFIDF_NMF_valid)\n",
    "scaled_valid_TFIDF_NMF = ss.transform(X_valid_TFIDF_NMF_normalized)\n",
    "\n",
    "logreg_classwt_NMF = LogisticRegression(C=0.05, penalty='l2', solver='liblinear', random_state=41, max_iter=500).fit(scaled_X_subtrain_TFIDF_NMF_ros, y_ros_resampled_subtrain)\n",
    "y_pred_classwt_NMF_subtrain = logreg_classwt_NMF.predict(scaled_X_subtrain_TFIDF_NMF_ros)\n",
    "y_pred_classwt_NMF_valid = logreg_classwt_NMF.predict(scaled_valid_TFIDF_NMF)\n",
    "\n",
    "print(roc_auc_score(y_ros_resampled_subtrain, y_pred_classwt_NMF_subtrain))\n",
    "print(roc_auc_score(y_valid, y_pred_classwt_NMF_valid))\n",
    "logreg_classwt_NMF.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:17:27.791479Z",
     "start_time": "2019-11-15T13:17:27.783555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "not, good, like, film, feel, make, disney, character, story, voice, song, no, look, time, version, live, go, remake, watch, animate, act, think, scene, action, animal, only, cgi, live action, bad, little\n",
      "\n",
      "Topic  2\n",
      "movie, good, enjoy, amaze, well, watch, disney, beautiful, make, time, kid, go, animate, like, old, give, want, bad, disappoint, thing, only, way, think, scene, no, come, little, nothing, real, act\n",
      "\n",
      "Topic  3\n",
      "great, smith, genie, job, music, cast, story, aladdin, amaze, remake, classic, good, actor, song, act, enjoy, singe, kid, new, think, animation, cgi, action, cartoon, make, little, live, disney, version, old\n",
      "\n",
      "Topic  4\n",
      "love, amaze, kid, story, song, smith, music, old, new, beautiful, go, version, genie, king, aladdin, think, lion king, lion, job, watch, disney, real, animal, singe, cartoon, time, add, want, cast, little\n",
      "\n",
      "Topic  5\n",
      "original, well, remake, watch, new, lack, lion, king, lion king, emotion, nothing, no, voice, song, version, add, like, animation, scene, way, animate, good, story, make, little, cartoon, music, amaze, time, live\n"
     ]
    }
   ],
   "source": [
    "display_topics(NMF_topics, tfidf_vec.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T12:20:46.910420Z",
     "start_time": "2019-11-15T12:18:39.151691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:07<00:00,  3.91it/s, best loss: 0.24201968977730548]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.24201968977730548,\n",
       " 'params': {'C': 0.05, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {'C': hp.choice('C', [0.001,0.05, 0.01,0.1,0.5,1,5, 10,50,100,500,1000,5000, 10000]),\n",
    "        'solver': hp.choice('solver', ['saga', 'liblinear']),\n",
    "        'penalty': hp.choice('penalty', ['l1','l2'])}\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Logistic Regerssion Machine Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    \n",
    "    model = LogisticRegression(**params, random_state=41, verbose=0,max_iter=500)\n",
    "    \n",
    "    best_score = cross_val_score(model, scaled_X_subtrain_TFIDF_NMF_ros, y_ros_resampled_subtrain, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "MAX_EVALS = 500\n",
    "trials = Trials()\n",
    "# We initialize trials object here to be able to see our results after algorithm is complete\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = MAX_EVALS,\n",
    "            trials= trials)\n",
    "best\n",
    "\n",
    "# To see which results were best\n",
    "best_results = sorted(trials.results, key = lambda x: x['loss'])\n",
    "best_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Trying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:32:43.012137Z",
     "start_time": "2019-11-15T13:32:22.451246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7053426766040182\n",
      "0.5869476877289378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.57157538,  0.45251235, -0.11680827, -0.11345774,  0.27151169]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subtrain, X_valid, y_subtrain, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=41)\n",
    "\n",
    "# #SUBTRAIN\n",
    "tvec = TfidfVectorizer(ngram_range=(1,5), min_df=0.05)\n",
    "testing_tfidf = tvec.fit_transform(X_subtrain.iloc[:,0].tolist())\n",
    "\n",
    "#SMOTE Oversampling\n",
    "X_smoted_subtrain, y_smoted_subtrain = SMOTE(random_state=0).fit_sample(testing_tfidf,y_subtrain)\n",
    "NMF_smote = NMF(n_components=5,random_state=10)\n",
    "TFIDF_NMF_smote = NMF_smote.fit_transform(X_smoted_subtrain)\n",
    "X_subtrain_TFIDF_NMF_smote_normalized = normalize(TFIDF_NMF_smote)\n",
    "\n",
    "X_TFIDF_NMF_smoted_subtrain = pd.DataFrame(X_subtrain_TFIDF_NMF_smote_normalized, columns = ['topic1', 'topic2', 'topic3', 'topic4', 'topic5'])\n",
    "y_TFIDF_NMF_smoted_subtrain = pd.DataFrame(y_smoted_subtrain, columns = ['sentiment'])\n",
    "\n",
    "ss= StandardScaler()\n",
    "scaled_X_subtrain_TFIDF_NMF_smoted = ss.fit_transform(X_TFIDF_NMF_smoted_subtrain)\n",
    "\n",
    "\n",
    "###VALID\n",
    "\n",
    "valid_corpus = X_valid.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "Pipeline_TFIDF_NMF_valid = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,5), min_df=0.05)),\n",
    "                ('NMF', NMF(n_components=5,random_state=10))])\n",
    "TFIDF_NMF_valid = Pipeline_TFIDF_NMF_valid.fit_transform(valid_corpus)\n",
    "\n",
    "X_valid_TFIDF_NMF_normalized = normalize(TFIDF_NMF_valid)\n",
    "scaled_valid_TFIDF_NMF = ss.transform(X_valid_TFIDF_NMF_normalized)\n",
    "\n",
    "logreg_classwt_NMF = LogisticRegression(C=0.001, penalty='l1', solver='liblinear', random_state=41, max_iter=500).fit(scaled_X_subtrain_TFIDF_NMF_smoted, y_smoted_subtrain)\n",
    "y_pred_classwt_NMF_subtrain = logreg_classwt_NMF.predict(scaled_X_subtrain_TFIDF_NMF_smoted)\n",
    "y_pred_classwt_NMF_valid = logreg_classwt_NMF.predict(scaled_valid_TFIDF_NMF)\n",
    "\n",
    "print(roc_auc_score(y_smoted_subtrain, y_pred_classwt_NMF_subtrain))\n",
    "print(roc_auc_score(y_valid, y_pred_classwt_NMF_valid))\n",
    "logreg_classwt_NMF.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:25:58.717154Z",
     "start_time": "2019-11-15T13:23:46.721934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:11<00:00,  3.79it/s, best loss: 0.22690399557119623]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.22690399557119623,\n",
       " 'params': {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {'C': hp.choice('C', [0.001,0.05, 0.01,0.1,0.5,1,5, 10,50,100,500,1000,5000, 10000]),\n",
    "        'solver': hp.choice('solver', ['saga', 'liblinear']),\n",
    "        'penalty': hp.choice('penalty', ['l1','l2'])}\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Logistic Regerssion Machine Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    \n",
    "    model = LogisticRegression(**params, random_state=41, verbose=0,max_iter=500)\n",
    "    \n",
    "    best_score = cross_val_score(model, scaled_X_subtrain_TFIDF_NMF_smoted, y_smoted_subtrain, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "MAX_EVALS = 500\n",
    "trials = Trials()\n",
    "# We initialize trials object here to be able to see our results after algorithm is complete\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = MAX_EVALS,\n",
    "            trials= trials)\n",
    "best\n",
    "\n",
    "# To see which results were best\n",
    "best_results = sorted(trials.results, key = lambda x: x['loss'])\n",
    "best_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:32:43.023134Z",
     "start_time": "2019-11-15T13:32:43.013803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "not, like, think, go, feel, voice, song, time, look, movie, character, watch, only, kid, scene, animal, actor, little, make, story, cgi, aladdin, act, way, old, cast, real, music, enjoy, version\n",
      "\n",
      "Topic  2\n",
      "movie, love, great, great movie, amaze, loved, enjoy, smith, awesome, kid, watch, beautiful, go, music, well, old, time, disney, job, fun, make, genie, aladdin, think, only, animate, like, way, little, song\n",
      "\n",
      "Topic  3\n",
      "original, well, new, watch, remake, song, scene, loved, lion, version, king, way, story, music, time, voice, little, fun, amaze, like, go, cgi, cast, no, think, awesome, love, beautiful, feel, animate\n",
      "\n",
      "Topic  4\n",
      "film, like, disney, make, remake, feel, no, character, animate, live, story, voice, version, action, lion, king, live action, well, classic, watch, look, act, time, new, scene, song, animal, cgi, little, only\n",
      "\n",
      "Topic  5\n",
      "good, smith, genie, great, job, aladdin, music, story, cast, think, enjoy, song, actor, fun, loved, amaze, act, little, version, awesome, make, only, cgi, scene, new, kid, character, go, way, old\n"
     ]
    }
   ],
   "source": [
    "display_topics(NMF_smote, tvec.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----DO NOT USE------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T12:36:28.475600Z",
     "start_time": "2019-11-15T12:36:28.470825Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#There's a cool LDA visualization available, but I did not end up using LDA... also it needs a corpus and a \"dictionary\"--which I couldn't get to work\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "flatlist = [word for word in corpus_subtrain]\n",
    "tokenized = tokenize(str(flatlist))\n",
    "list(tokenized)\n",
    "\n",
    "gensim_corpus = list(tokenized)\n",
    "dictionary = Dictionary(list(tokenized))\n",
    "\n",
    "pyLDAvis.gensim.prepare(lda_subtrain,gensim_corpus_subtrain, ___DICTIONARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T12:37:35.907758Z",
     "start_time": "2019-11-15T12:36:30.583081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6680918480335074\n",
      "0.4983974358974359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.17658163, -0.31929957,  0.41328625, -0.07867729,  0.33119805,\n",
       "        -0.19865915,  0.08573398, -0.04827216, -0.59259475,  0.13543375,\n",
       "        -0.25661444,  0.37652611, -0.15059132, -0.33822592]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subtrain, X_valid, y_subtrain, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=41)\n",
    "\n",
    "###SUBTRAIN\n",
    "corpus_subtrain = X_subtrain.iloc[:,0].tolist()\n",
    "\n",
    "tfidfvec = TfidfVectorizer(ngram_range=(1,5), min_df=0.05, stop_words=['movie', 'film'])\n",
    "doc_word_tfidfvec_subtrain = tfidfvec.fit_transform(corpus_subtrain)\n",
    "\n",
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "gensim_corpus_subtrain = matutils.Sparse2Corpus(doc_word_tfidfvec_subtrain.transpose())\n",
    "\n",
    "#Map matrix rows to words (tokens)\n",
    "#We need to save a mapping (dict) of row id to word (token) for later use by gensim:\n",
    "id2word = dict((v, k) for k, v in tfidfvec.vocabulary_.items())\n",
    "\n",
    "# Create lda model (equivalent to \"fit\" in sklearn)\n",
    "lda_subtrain = models.LdaModel(corpus=gensim_corpus_subtrain, num_topics=14, id2word=id2word, passes=5)\n",
    "\n",
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus_subtrain = lda_subtrain[gensim_corpus_subtrain]\n",
    "\n",
    "\n",
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs_subtrain = [doc for doc in lda_corpus_subtrain]\n",
    "\n",
    "tuples_doc_topic_df = pd.DataFrame(lda_docs_subtrain,columns=['topic1','topic2','topic3','topic4','topic5','topic6','topic7','topic8','topic9','topic10','topic11','topic12','topic13','topic14'])\n",
    "tuples_doc_topic_df['topic1'] = tuples_doc_topic_df['topic1'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic2'] = tuples_doc_topic_df['topic2'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic3'] = tuples_doc_topic_df['topic3'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic4'] = tuples_doc_topic_df['topic4'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic5'] = tuples_doc_topic_df['topic5'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic6'] = tuples_doc_topic_df['topic6'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic7'] = tuples_doc_topic_df['topic7'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic8'] = tuples_doc_topic_df['topic8'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic9'] = tuples_doc_topic_df['topic9'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic10'] = tuples_doc_topic_df['topic10'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic11'] = tuples_doc_topic_df['topic11'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic12'] = tuples_doc_topic_df['topic12'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic13'] = tuples_doc_topic_df['topic13'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic14'] = tuples_doc_topic_df['topic14'].str[1].astype(float)\n",
    "\n",
    "X_subtrain_TFIDF_LDA_normalized = normalize(tuples_doc_topic_df)\n",
    "ss = StandardScaler()\n",
    "scaled_subtrain_TFIDF_LDA = ss.fit_transform(X_subtrain_TFIDF_LDA_normalized)\n",
    "\n",
    "\n",
    "###VALID\n",
    "\n",
    "corpus_valid = X_valid.iloc[:,0].tolist()  #convert from dataframe to series, to transform into list of reviews\n",
    "\n",
    "tfidfvec = TfidfVectorizer(ngram_range=(1,5), stop_words=['movie', 'film'])\n",
    "doc_word_tfidfvec_valid = tfidfvec.fit_transform(corpus_valid)\n",
    "\n",
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "gensim_corpus_valid = matutils.Sparse2Corpus(doc_word_tfidfvec_valid.transpose())\n",
    "\n",
    "#Map matrix rows to words (tokens)\n",
    "#We need to save a mapping (dict) of row id to word (token) for later use by gensim:\n",
    "id2word = dict((v, k) for k, v in tfidfvec.vocabulary_.items())\n",
    "\n",
    "# Create lda model (equivalent to \"fit\" in sklearn)\n",
    "lda_valid = models.LdaModel(corpus=gensim_corpus_valid, num_topics=14, id2word=id2word, passes=5)\n",
    "\n",
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus_valid = lda_valid[gensim_corpus_valid]\n",
    "\n",
    "\n",
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs_valid = [doc for doc in lda_corpus_valid]\n",
    "\n",
    "tuples_doc_topic_df = pd.DataFrame(lda_docs_valid,columns=['topic1','topic2','topic3','topic4','topic5','topic6','topic7','topic8','topic9','topic10','topic11','topic12','topic13','topic14'])\n",
    "tuples_doc_topic_df['topic1'] = tuples_doc_topic_df['topic1'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic2'] = tuples_doc_topic_df['topic2'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic3'] = tuples_doc_topic_df['topic3'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic4'] = tuples_doc_topic_df['topic4'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic5'] = tuples_doc_topic_df['topic5'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic6'] = tuples_doc_topic_df['topic6'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic7'] = tuples_doc_topic_df['topic7'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic8'] = tuples_doc_topic_df['topic8'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic9'] = tuples_doc_topic_df['topic9'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic10'] = tuples_doc_topic_df['topic10'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic11'] = tuples_doc_topic_df['topic11'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic12'] = tuples_doc_topic_df['topic12'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic13'] = tuples_doc_topic_df['topic13'].str[1].astype(float)\n",
    "tuples_doc_topic_df['topic14'] = tuples_doc_topic_df['topic14'].str[1].astype(float)\n",
    "\n",
    "X_valid_TFIDF_LDA_normalized = normalize(tuples_doc_topic_df)\n",
    "scaled_valid_TFIDF_LDA = ss.transform(X_valid_TFIDF_LDA_normalized)\n",
    "\n",
    "\n",
    "logreg_classwt_LDA = LogisticRegression(C=0.5, penalty='l2', solver='saga', class_weight='balanced', random_state=41, max_iter=500).fit(scaled_subtrain_TFIDF_LDA, y_subtrain)\n",
    "y_pred_classwt_LDA_subtrain = logreg_classwt_LDA.predict(scaled_subtrain_TFIDF_LDA)\n",
    "y_pred_classwt_LDA_valid = logreg_classwt_LDA.predict(scaled_valid_TFIDF_LDA)\n",
    "\n",
    "print(roc_auc_score(y_subtrain, y_pred_classwt_LDA_subtrain))\n",
    "print(roc_auc_score(y_valid, y_pred_classwt_LDA_valid))\n",
    "logreg_classwt_LDA.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T12:39:03.228874Z",
     "start_time": "2019-11-15T12:39:03.225011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(gensim_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T12:38:48.703902Z",
     "start_time": "2019-11-15T12:38:48.684325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{48023: 'best',\n",
       " 2261: '2019',\n",
       " 48396: 'better',\n",
       " 124388: 'endgame',\n",
       " 282811: 'no',\n",
       " 114000: 'doubt',\n",
       " 48024: 'best 2019',\n",
       " 2306: '2019 better',\n",
       " 48420: 'better endgame',\n",
       " 124389: 'endgame no',\n",
       " 283088: 'no doubt',\n",
       " 48025: 'best 2019 better',\n",
       " 2307: '2019 better endgame',\n",
       " 48421: 'better endgame no',\n",
       " 124390: 'endgame no doubt',\n",
       " 48026: 'best 2019 better endgame',\n",
       " 2308: '2019 better endgame no',\n",
       " 48422: 'better endgame no doubt',\n",
       " 48027: 'best 2019 better endgame no',\n",
       " 2309: '2019 better endgame no doubt',\n",
       " 4616: 'absolutely',\n",
       " 244064: 'love',\n",
       " 158204: 'fresh',\n",
       " 279213: 'new',\n",
       " 380967: 'song',\n",
       " 170585: 'good',\n",
       " 78749: 'classic',\n",
       " 377432: 'smith',\n",
       " 192048: 'hold',\n",
       " 163107: 'genie',\n",
       " 424580: 'twist',\n",
       " 47467: 'beloved',\n",
       " 69524: 'character',\n",
       " 325629: 'pleasantly',\n",
       " 401507: 'surprise',\n",
       " 4988: 'absolutely love',\n",
       " 245388: 'love fresh',\n",
       " 158354: 'fresh new',\n",
       " 280899: 'new song',\n",
       " 381942: 'song good',\n",
       " 171477: 'good classic',\n",
       " 79759: 'classic love',\n",
       " 247402: 'love smith',\n",
       " 378709: 'smith hold',\n",
       " 192114: 'hold genie',\n",
       " 164673: 'genie twist',\n",
       " 424602: 'twist beloved',\n",
       " 47533: 'beloved character',\n",
       " 71718: 'character pleasantly',\n",
       " 325638: 'pleasantly surprise',\n",
       " 5046: 'absolutely love fresh',\n",
       " 245389: 'love fresh new',\n",
       " 158366: 'fresh new song',\n",
       " 281020: 'new song good',\n",
       " 381952: 'song good classic',\n",
       " 171487: 'good classic love',\n",
       " 79769: 'classic love smith',\n",
       " 247466: 'love smith hold',\n",
       " 378713: 'smith hold genie',\n",
       " 192115: 'hold genie twist',\n",
       " 164674: 'genie twist beloved',\n",
       " 424603: 'twist beloved character',\n",
       " 47551: 'beloved character pleasantly',\n",
       " 71719: 'character pleasantly surprise',\n",
       " 5047: 'absolutely love fresh new',\n",
       " 245390: 'love fresh new song',\n",
       " 158367: 'fresh new song good',\n",
       " 281021: 'new song good classic',\n",
       " 381953: 'song good classic love',\n",
       " 171488: 'good classic love smith',\n",
       " 79770: 'classic love smith hold',\n",
       " 247467: 'love smith hold genie',\n",
       " 378714: 'smith hold genie twist',\n",
       " 192116: 'hold genie twist beloved',\n",
       " 164675: 'genie twist beloved character',\n",
       " 424604: 'twist beloved character pleasantly',\n",
       " 47552: 'beloved character pleasantly surprise',\n",
       " 5048: 'absolutely love fresh new song',\n",
       " 245391: 'love fresh new song good',\n",
       " 158368: 'fresh new song good classic',\n",
       " 281022: 'new song good classic love',\n",
       " 381954: 'song good classic love smith',\n",
       " 171489: 'good classic love smith hold',\n",
       " 79771: 'classic love smith hold genie',\n",
       " 247468: 'love smith hold genie twist',\n",
       " 378715: 'smith hold genie twist beloved',\n",
       " 192117: 'hold genie twist beloved character',\n",
       " 164676: 'genie twist beloved character pleasantly',\n",
       " 424605: 'twist beloved character pleasantly surprise',\n",
       " 20959: 'amaze',\n",
       " 285573: 'not',\n",
       " 218434: 'know',\n",
       " 317411: 'people',\n",
       " 93917: 'criticize',\n",
       " 38576: 'badly',\n",
       " 458790: 'yes',\n",
       " 242661: 'lot',\n",
       " 88796: 'content',\n",
       " 305115: 'original',\n",
       " 104077: 'dialogue',\n",
       " 439502: 'want',\n",
       " 132440: 'exact',\n",
       " 346310: 'remake',\n",
       " 430322: 'version',\n",
       " 58909: 'build',\n",
       " 42501: 'beautiful',\n",
       " 21280: 'amaze classic',\n",
       " 79895: 'classic not',\n",
       " 290585: 'not know',\n",
       " 219321: 'know people',\n",
       " 317641: 'people criticize',\n",
       " 93918: 'criticize badly',\n",
       " 38604: 'badly yes',\n",
       " 458997: 'yes lot',\n",
       " 242806: 'lot content',\n",
       " 88829: 'content original',\n",
       " 306551: 'original dialogue',\n",
       " 104374: 'dialogue want',\n",
       " 439708: 'want exact',\n",
       " 132544: 'exact remake',\n",
       " 348929: 'remake version',\n",
       " 430693: 'version build',\n",
       " 58959: 'build original',\n",
       " 307349: 'original good',\n",
       " 170635: 'good absolutely',\n",
       " 4753: 'absolutely beautiful',\n",
       " 21284: 'amaze classic not',\n",
       " 79915: 'classic not know',\n",
       " 290729: 'not know people',\n",
       " 219322: 'know people criticize',\n",
       " 317642: 'people criticize badly',\n",
       " 93919: 'criticize badly yes',\n",
       " 38605: 'badly yes lot',\n",
       " 458998: 'yes lot content',\n",
       " 242807: 'lot content original',\n",
       " 88830: 'content original dialogue',\n",
       " 306558: 'original dialogue want',\n",
       " 104375: 'dialogue want exact',\n",
       " 439709: 'want exact remake',\n",
       " 132556: 'exact remake version',\n",
       " 348933: 'remake version build',\n",
       " 430694: 'version build original',\n",
       " 58960: 'build original good',\n",
       " 307350: 'original good absolutely',\n",
       " 170636: 'good absolutely beautiful',\n",
       " 21285: 'amaze classic not know',\n",
       " 79918: 'classic not know people',\n",
       " 290730: 'not know people criticize',\n",
       " 219323: 'know people criticize badly',\n",
       " 317643: 'people criticize badly yes',\n",
       " 93920: 'criticize badly yes lot',\n",
       " 38606: 'badly yes lot content',\n",
       " 458999: 'yes lot content original',\n",
       " 242808: 'lot content original dialogue',\n",
       " 88831: 'content original dialogue want',\n",
       " 306559: 'original dialogue want exact',\n",
       " 104376: 'dialogue want exact remake',\n",
       " 439710: 'want exact remake version',\n",
       " 132557: 'exact remake version build',\n",
       " 348934: 'remake version build original',\n",
       " 430695: 'version build original good',\n",
       " 58961: 'build original good absolutely',\n",
       " 307351: 'original good absolutely beautiful',\n",
       " 21286: 'amaze classic not know people',\n",
       " 79919: 'classic not know people criticize',\n",
       " 290731: 'not know people criticize badly',\n",
       " 219324: 'know people criticize badly yes',\n",
       " 317644: 'people criticize badly yes lot',\n",
       " 93921: 'criticize badly yes lot content',\n",
       " 38607: 'badly yes lot content original',\n",
       " 459000: 'yes lot content original dialogue',\n",
       " 242809: 'lot content original dialogue want',\n",
       " 88832: 'content original dialogue want exact',\n",
       " 306560: 'original dialogue want exact remake',\n",
       " 104377: 'dialogue want exact remake version',\n",
       " 439711: 'want exact remake version build',\n",
       " 132558: 'exact remake version build original',\n",
       " 348935: 'remake version build original good',\n",
       " 430696: 'version build original good absolutely',\n",
       " 58962: 'build original good absolutely beautiful',\n",
       " 28436: 'animation',\n",
       " 200709: 'incredible',\n",
       " 325539: 'player',\n",
       " 56975: 'bring',\n",
       " 178006: 'great',\n",
       " 159286: 'fun',\n",
       " 206542: 'james',\n",
       " 116273: 'earl',\n",
       " 210543: 'jones',\n",
       " 446610: 'well',\n",
       " 277048: 'need',\n",
       " 28889: 'animation incredible',\n",
       " 200811: 'incredible character',\n",
       " 70681: 'character good',\n",
       " 173106: 'good know',\n",
       " 219351: 'know player',\n",
       " 325540: 'player bring',\n",
       " 57454: 'bring great',\n",
       " 179531: 'great fun',\n",
       " 159757: 'fun james',\n",
       " 206608: 'james earl',\n",
       " 116274: 'earl jones',\n",
       " 210737: 'jones well',\n",
       " 448306: 'well need',\n",
       " 277369: 'need know',\n",
       " 28893: 'animation incredible character',\n",
       " 200815: 'incredible character good',\n",
       " 70745: 'character good know',\n",
       " 173140: 'good know player',\n",
       " 219352: 'know player bring',\n",
       " 325541: 'player bring great',\n",
       " 57458: 'bring great fun',\n",
       " 179542: 'great fun james',\n",
       " 159758: 'fun james earl',\n",
       " 206609: 'james earl jones',\n",
       " 116400: 'earl jones well',\n",
       " 210738: 'jones well need',\n",
       " 448307: 'well need know',\n",
       " 28894: 'animation incredible character good',\n",
       " 200816: 'incredible character good know',\n",
       " 70746: 'character good know player',\n",
       " 173141: 'good know player bring',\n",
       " 219353: 'know player bring great',\n",
       " 325542: 'player bring great fun',\n",
       " 57459: 'bring great fun james',\n",
       " 179543: 'great fun james earl',\n",
       " 159759: 'fun james earl jones',\n",
       " 206683: 'james earl jones well',\n",
       " 116401: 'earl jones well need',\n",
       " 210739: 'jones well need know',\n",
       " 28895: 'animation incredible character good know',\n",
       " 200817: 'incredible character good know player',\n",
       " 70747: 'character good know player bring',\n",
       " 173142: 'good know player bring great',\n",
       " 219354: 'know player bring great fun',\n",
       " 325543: 'player bring great fun james',\n",
       " 57460: 'bring great fun james earl',\n",
       " 179544: 'great fun james earl jones',\n",
       " 159760: 'fun james earl jones well',\n",
       " 206684: 'james earl jones well need',\n",
       " 116402: 'earl jones well need know',\n",
       " 167839: 'go',\n",
       " 85181: 'compare',\n",
       " 26240: 'animate',\n",
       " 313222: 'overall',\n",
       " 410574: 'think',\n",
       " 397204: 'struggle',\n",
       " 361029: 'scene',\n",
       " 130172: 'especially',\n",
       " 96321: 'dance',\n",
       " 36066: 'awesome',\n",
       " 90189: 'costume',\n",
       " 169215: 'go not',\n",
       " 295671: 'not want',\n",
       " 439626: 'want compare',\n",
       " 85230: 'compare animate',\n",
       " 27901: 'animate version',\n",
       " 432025: 'version overall',\n",
       " 313965: 'overall think',\n",
       " 411499: 'think great',\n",
       " 181876: 'great smith',\n",
       " 379485: 'smith struggle',\n",
       " 397242: 'struggle scene',\n",
       " 361544: 'scene especially',\n",
       " 130260: 'especially dance',\n",
       " 96634: 'dance scene',\n",
       " 361174: 'scene awesome',\n",
       " 36220: 'awesome costume',\n",
       " 169258: 'go not want',\n",
       " 295687: 'not want compare',\n",
       " 439627: 'want compare animate',\n",
       " 85238: 'compare animate version',\n",
       " 28138: 'animate version overall',\n",
       " 432029: 'version overall think',\n",
       " 313972: 'overall think great',\n",
       " 411546: 'think great smith',\n",
       " 181954: 'great smith struggle',\n",
       " 379486: 'smith struggle scene',\n",
       " 397243: 'struggle scene especially',\n",
       " 361545: 'scene especially dance',\n",
       " 130261: 'especially dance scene',\n",
       " 96639: 'dance scene awesome',\n",
       " 361175: 'scene awesome costume',\n",
       " 169259: 'go not want compare',\n",
       " 295688: 'not want compare animate',\n",
       " 439628: 'want compare animate version',\n",
       " 85245: 'compare animate version overall',\n",
       " 28141: 'animate version overall think',\n",
       " 432030: 'version overall think great',\n",
       " 313975: 'overall think great smith',\n",
       " 411547: 'think great smith struggle',\n",
       " 181955: 'great smith struggle scene',\n",
       " 379487: 'smith struggle scene especially',\n",
       " 397244: 'struggle scene especially dance',\n",
       " 361546: 'scene especially dance scene',\n",
       " 130262: 'especially dance scene awesome',\n",
       " 96640: 'dance scene awesome costume',\n",
       " 169260: 'go not want compare animate',\n",
       " 295689: 'not want compare animate version',\n",
       " 439629: 'want compare animate version overall',\n",
       " 85246: 'compare animate version overall think',\n",
       " 28142: 'animate version overall think great',\n",
       " 432031: 'version overall think great smith',\n",
       " 313976: 'overall think great smith struggle',\n",
       " 411548: 'think great smith struggle scene',\n",
       " 181956: 'great smith struggle scene especially',\n",
       " 379488: 'smith struggle scene especially dance',\n",
       " 397245: 'struggle scene especially dance scene',\n",
       " 361547: 'scene especially dance scene awesome',\n",
       " 130263: 'especially dance scene awesome costume',\n",
       " 135373: 'expect',\n",
       " 272175: 'music',\n",
       " 400281: 'superb',\n",
       " 300474: 'old',\n",
       " 153901: 'fit',\n",
       " 4099: 'able',\n",
       " 406090: 'tell',\n",
       " 134537: 'excite',\n",
       " 83051: 'come',\n",
       " 116009: 'dvd',\n",
       " 246138: 'love love',\n",
       " 245236: 'love expect',\n",
       " 135729: 'expect good',\n",
       " 173913: 'good not',\n",
       " 295885: 'not well',\n",
       " 446779: 'well animate',\n",
       " 431762: 'version music',\n",
       " 273537: 'music superb',\n",
       " 400404: 'superb old',\n",
       " 301108: 'old new',\n",
       " 382544: 'song new',\n",
       " 381871: 'song fit',\n",
       " 154000: 'fit good',\n",
       " 285921: 'not animate',\n",
       " 431825: 'version not',\n",
       " 285616: 'not able',\n",
       " 4305: 'able tell',\n",
       " 406529: 'tell old',\n",
       " 279847: 'new excite',\n",
       " 134592: 'excite come',\n",
       " 83377: 'come dvd',\n",
       " 246173: 'love love love',\n",
       " 246159: 'love love expect',\n",
       " 245240: 'love expect good',\n",
       " 135741: 'expect good not',\n",
       " 174086: 'good not well',\n",
       " 295890: 'not well animate',\n",
       " 446795: 'well animate version',\n",
       " 28096: 'animate version music',\n",
       " 431771: 'version music superb',\n",
       " 273538: 'music superb old',\n",
       " 400405: 'superb old new',\n",
       " 301135: 'old new song',\n",
       " 281102: 'new song new',\n",
       " 382567: 'song new song',\n",
       " 281011: 'new song fit',\n",
       " 381875: 'song fit good',\n",
       " 154010: 'fit good not',\n",
       " 173917: 'good not animate',\n",
       " 285936: 'not animate version',\n",
       " 28121: 'animate version not',\n",
       " 431829: 'version not able',\n",
       " 285640: 'not able tell',\n",
       " 4306: 'able tell old',\n",
       " 406530: 'tell old new',\n",
       " 301118: 'old new excite',\n",
       " 279854: 'new excite come',\n",
       " 134593: 'excite come dvd',\n",
       " 246176: 'love love love expect',\n",
       " 246160: 'love love expect good',\n",
       " 245241: 'love expect good not',\n",
       " 135744: 'expect good not well',\n",
       " 174087: 'good not well animate',\n",
       " 295891: 'not well animate version',\n",
       " 446804: 'well animate version music',\n",
       " 28099: 'animate version music superb',\n",
       " 431772: 'version music superb old',\n",
       " 273539: 'music superb old new',\n",
       " 400406: 'superb old new song',\n",
       " 301138: 'old new song new',\n",
       " 281111: 'new song new song',\n",
       " 382572: 'song new song fit',\n",
       " 281014: 'new song fit good',\n",
       " 381876: 'song fit good not',\n",
       " 154011: 'fit good not animate',\n",
       " 173918: 'good not animate version',\n",
       " 285937: 'not animate version not',\n",
       " 28122: 'animate version not able',\n",
       " 431830: 'version not able tell',\n",
       " 285641: 'not able tell old',\n",
       " 4307: 'able tell old new',\n",
       " 406531: 'tell old new excite',\n",
       " 301119: 'old new excite come',\n",
       " 279855: 'new excite come dvd',\n",
       " 246177: 'love love love expect good',\n",
       " 246161: 'love love expect good not',\n",
       " 245242: 'love expect good not well',\n",
       " 135745: 'expect good not well animate',\n",
       " 174088: 'good not well animate version',\n",
       " 295892: 'not well animate version music',\n",
       " 446805: 'well animate version music superb',\n",
       " 28100: 'animate version music superb old',\n",
       " 431773: 'version music superb old new',\n",
       " 273540: 'music superb old new song',\n",
       " 400407: 'superb old new song new',\n",
       " 301139: 'old new song new song',\n",
       " 281112: 'new song new song fit',\n",
       " 382573: 'song new song fit good',\n",
       " 281015: 'new song fit good not',\n",
       " 381877: 'song fit good not animate',\n",
       " 154012: 'fit good not animate version',\n",
       " 173919: 'good not animate version not',\n",
       " 285938: 'not animate version not able',\n",
       " 28123: 'animate version not able tell',\n",
       " 431831: 'version not able tell old',\n",
       " 285642: 'not able tell old new',\n",
       " 4308: 'able tell old new excite',\n",
       " 406532: 'tell old new excite come',\n",
       " 301120: 'old new excite come dvd',\n",
       " 50640: 'bite',\n",
       " 375639: 'skeptical',\n",
       " 419662: 'trailer',\n",
       " 146096: 'fav',\n",
       " 457953: 'year',\n",
       " 356312: 'role',\n",
       " 319678: 'perfectly',\n",
       " 51298: 'bite skeptical',\n",
       " 375753: 'skeptical trailer',\n",
       " 419718: 'trailer fav',\n",
       " 146113: 'fav year',\n",
       " 458158: 'year fit',\n",
       " 154130: 'fit role',\n",
       " 356956: 'role perfectly',\n",
       " 51308: 'bite skeptical trailer',\n",
       " 375754: 'skeptical trailer fav',\n",
       " 419719: 'trailer fav year',\n",
       " 146114: 'fav year fit',\n",
       " 458159: 'year fit role',\n",
       " 154143: 'fit role perfectly',\n",
       " 51309: 'bite skeptical trailer fav',\n",
       " 375755: 'skeptical trailer fav year',\n",
       " 419720: 'trailer fav year fit',\n",
       " 146115: 'fav year fit role',\n",
       " 458160: 'year fit role perfectly',\n",
       " 51310: 'bite skeptical trailer fav year',\n",
       " 375756: 'skeptical trailer fav year fit',\n",
       " 419721: 'trailer fav year fit role',\n",
       " 146116: 'fav year fit role perfectly',\n",
       " 127716: 'entertain',\n",
       " 144896: 'far',\n",
       " 128363: 'entertain year',\n",
       " 458129: 'year far',\n",
       " 128364: 'entertain year far',\n",
       " 134396: 'exceptional',\n",
       " 385712: 'special',\n",
       " 117287: 'effect',\n",
       " 61154: 'carriage',\n",
       " 34015: 'attendant',\n",
       " 302134: 'only',\n",
       " 205487: 'issue',\n",
       " 155720: 'folk',\n",
       " 227321: 'like',\n",
       " 239739: 'long',\n",
       " 127021: 'enough',\n",
       " 330832: 'presentation',\n",
       " 147822: 'feature',\n",
       " 323781: 'place',\n",
       " 188497: 'heart',\n",
       " 324414: 'play',\n",
       " 414491: 'time',\n",
       " 455378: 'world',\n",
       " 202406: 'innocent',\n",
       " 215586: 'kind',\n",
       " 373134: 'sing',\n",
       " 119283: 'element',\n",
       " 223631: 'leave',\n",
       " 366709: 'sense',\n",
       " 36008: 'awe',\n",
       " 193510: 'hope',\n",
       " 417528: 'today',\n",
       " 187258: 'harsh',\n",
       " 434053: 'violence',\n",
       " 101788: 'depict',\n",
       " 132064: 'evil',\n",
       " 99418: 'decide',\n",
       " 253183: 'make',\n",
       " 416717: 'timeless',\n",
       " 392294: 'story',\n",
       " 190933: 'highlight',\n",
       " 328670: 'positive',\n",
       " 249860: 'low',\n",
       " 278004: 'negative',\n",
       " 340027: 'real',\n",
       " 134418: 'exceptional great',\n",
       " 182039: 'great special',\n",
       " 385764: 'special effect',\n",
       " 117808: 'effect love',\n",
       " 244661: 'love carriage',\n",
       " 61155: 'carriage attendant',\n",
       " 34016: 'attendant only',\n",
       " 302823: 'only issue',\n",
       " 205543: 'issue folk',\n",
       " 155734: 'folk like',\n",
       " 229700: 'like long',\n",
       " 239831: 'long enough',\n",
       " 127448: 'enough presentation',\n",
       " 330860: 'presentation original',\n",
       " 305623: 'original animation',\n",
       " 28751: 'animation feature',\n",
       " 147921: 'feature hold',\n",
       " 192204: 'hold special',\n",
       " 386109: 'special place',\n",
       " 323919: 'place heart',\n",
       " 188872: 'heart play',\n",
       " 325456: 'play time',\n",
       " 416662: 'time world',\n",
       " 455622: 'world innocent',\n",
       " 202427: 'innocent kind',\n",
       " 215937: 'kind song',\n",
       " 383164: 'song sing',\n",
       " 373619: 'sing special',\n",
       " 386033: 'special element',\n",
       " 119380: 'element leave',\n",
       " 224042: 'leave sense',\n",
       " 366714: 'sense awe',\n",
       " 36016: 'awe hope',\n",
       " 193826: 'hope today',\n",
       " 417706: 'today world',\n",
       " 455598: 'world harsh',\n",
       " 187303: 'harsh violence',\n",
       " 434087: 'violence new',\n",
       " 281586: 'new version',\n",
       " 430936: 'version depict',\n",
       " 101789: 'depict evil',\n",
       " 132297: 'evil world',\n",
       " 455580: 'world good',\n",
       " 175589: 'good time',\n",
       " 414878: 'time decide',\n",
       " 99484: 'decide make',\n",
       " 253848: 'make classic',\n",
       " 80502: 'classic timeless',\n",
       " 416767: 'timeless story',\n",
       " 393657: 'story highlight',\n",
       " 190976: 'highlight positive',\n",
       " 328712: 'positive low',\n",
       " 249973: 'low negative',\n",
       " 278035: 'negative enough',\n",
       " 127372: 'enough negative',\n",
       " 278085: 'negative real',\n",
       " 341281: 'real world',\n",
       " 134419: 'exceptional great special',\n",
       " 182040: 'great special effect',\n",
       " 385896: 'special effect love',\n",
       " 117812: 'effect love carriage',\n",
       " 244662: 'love carriage attendant',\n",
       " 61156: 'carriage attendant only',\n",
       " 34017: 'attendant only issue',\n",
       " 302827: 'only issue folk',\n",
       " 205544: 'issue folk like',\n",
       " 155735: 'folk like long',\n",
       " 229701: 'like long enough',\n",
       " 239835: 'long enough presentation',\n",
       " 127449: 'enough presentation original',\n",
       " 330861: 'presentation original animation',\n",
       " 305627: 'original animation feature',\n",
       " 28752: 'animation feature hold',\n",
       " 147922: 'feature hold special',\n",
       " 192205: 'hold special place',\n",
       " 386113: 'special place heart',\n",
       " 323920: 'place heart play',\n",
       " 188873: 'heart play time',\n",
       " 325463: 'play time world',\n",
       " 416663: 'time world innocent',\n",
       " 455623: 'world innocent kind',\n",
       " 202428: 'innocent kind song',\n",
       " 215938: 'kind song sing',\n",
       " 383208: 'song sing special',\n",
       " 373620: 'sing special element',\n",
       " 386034: 'special element leave',\n",
       " 119381: 'element leave sense',\n",
       " 224043: 'leave sense awe',\n",
       " 366715: 'sense awe hope',\n",
       " 36017: 'awe hope today',\n",
       " 193827: 'hope today world',\n",
       " 417713: 'today world harsh',\n",
       " 455599: 'world harsh violence',\n",
       " 187304: 'harsh violence new',\n",
       " 434088: 'violence new version',\n",
       " 281620: 'new version depict',\n",
       " 430937: 'version depict evil',\n",
       " 101790: 'depict evil world',\n",
       " 132298: 'evil world good',\n",
       " 455587: 'world good time',\n",
       " 175593: 'good time decide',\n",
       " 414879: 'time decide make',\n",
       " 99485: 'decide make classic',\n",
       " 253859: 'make classic timeless',\n",
       " 80503: 'classic timeless story',\n",
       " 416768: 'timeless story highlight',\n",
       " 393658: 'story highlight positive',\n",
       " 190977: 'highlight positive low',\n",
       " 328713: 'positive low negative',\n",
       " 249974: 'low negative enough',\n",
       " 278036: 'negative enough negative',\n",
       " 127373: 'enough negative real',\n",
       " 278086: 'negative real world',\n",
       " 134420: 'exceptional great special effect',\n",
       " 182049: 'great special effect love',\n",
       " 385897: 'special effect love carriage',\n",
       " 117813: 'effect love carriage attendant',\n",
       " 244663: 'love carriage attendant only',\n",
       " 61157: 'carriage attendant only issue',\n",
       " 34018: 'attendant only issue folk',\n",
       " 302828: 'only issue folk like',\n",
       " 205545: 'issue folk like long',\n",
       " 155736: 'folk like long enough',\n",
       " 229702: 'like long enough presentation',\n",
       " 239836: 'long enough presentation original',\n",
       " 127450: 'enough presentation original animation',\n",
       " 330862: 'presentation original animation feature',\n",
       " 305628: 'original animation feature hold',\n",
       " 28753: 'animation feature hold special',\n",
       " 147923: 'feature hold special place',\n",
       " 192206: 'hold special place heart',\n",
       " 386114: 'special place heart play',\n",
       " 323921: 'place heart play time',\n",
       " 188874: 'heart play time world',\n",
       " 325464: 'play time world innocent',\n",
       " 416664: 'time world innocent kind',\n",
       " 455624: 'world innocent kind song',\n",
       " 202429: 'innocent kind song sing',\n",
       " 215939: 'kind song sing special',\n",
       " 383209: 'song sing special element',\n",
       " 373621: 'sing special element leave',\n",
       " 386035: 'special element leave sense',\n",
       " 119382: 'element leave sense awe',\n",
       " 224044: 'leave sense awe hope',\n",
       " 366716: 'sense awe hope today',\n",
       " 36018: 'awe hope today world',\n",
       " 193828: 'hope today world harsh',\n",
       " 417714: 'today world harsh violence',\n",
       " 455600: 'world harsh violence new',\n",
       " 187305: 'harsh violence new version',\n",
       " 434089: 'violence new version depict',\n",
       " 281621: 'new version depict evil',\n",
       " 430938: 'version depict evil world',\n",
       " 101791: 'depict evil world good',\n",
       " 132299: 'evil world good time',\n",
       " 455588: 'world good time decide',\n",
       " 175594: 'good time decide make',\n",
       " 414880: 'time decide make classic',\n",
       " 99486: 'decide make classic timeless',\n",
       " 253860: 'make classic timeless story',\n",
       " 80504: 'classic timeless story highlight',\n",
       " 416769: 'timeless story highlight positive',\n",
       " 393659: 'story highlight positive low',\n",
       " 190978: 'highlight positive low negative',\n",
       " 328714: 'positive low negative enough',\n",
       " 249975: 'low negative enough negative',\n",
       " 278037: 'negative enough negative real',\n",
       " 127374: 'enough negative real world',\n",
       " 134421: 'exceptional great special effect love',\n",
       " 182050: 'great special effect love carriage',\n",
       " 385898: 'special effect love carriage attendant',\n",
       " 117814: 'effect love carriage attendant only',\n",
       " 244664: 'love carriage attendant only issue',\n",
       " 61158: 'carriage attendant only issue folk',\n",
       " 34019: 'attendant only issue folk like',\n",
       " 302829: 'only issue folk like long',\n",
       " 205546: 'issue folk like long enough',\n",
       " 155737: 'folk like long enough presentation',\n",
       " 229703: 'like long enough presentation original',\n",
       " 239837: 'long enough presentation original animation',\n",
       " 127451: 'enough presentation original animation feature',\n",
       " 330863: 'presentation original animation feature hold',\n",
       " 305629: 'original animation feature hold special',\n",
       " 28754: 'animation feature hold special place',\n",
       " 147924: 'feature hold special place heart',\n",
       " 192207: 'hold special place heart play',\n",
       " 386115: 'special place heart play time',\n",
       " 323922: 'place heart play time world',\n",
       " 188875: 'heart play time world innocent',\n",
       " 325465: 'play time world innocent kind',\n",
       " 416665: 'time world innocent kind song',\n",
       " 455625: 'world innocent kind song sing',\n",
       " 202430: 'innocent kind song sing special',\n",
       " 215940: 'kind song sing special element',\n",
       " 383210: 'song sing special element leave',\n",
       " 373622: 'sing special element leave sense',\n",
       " 386036: 'special element leave sense awe',\n",
       " 119383: 'element leave sense awe hope',\n",
       " 224045: 'leave sense awe hope today',\n",
       " 366717: 'sense awe hope today world',\n",
       " 36019: 'awe hope today world harsh',\n",
       " 193829: 'hope today world harsh violence',\n",
       " 417715: 'today world harsh violence new',\n",
       " 455601: 'world harsh violence new version',\n",
       " 187306: 'harsh violence new version depict',\n",
       " 434090: 'violence new version depict evil',\n",
       " 281622: 'new version depict evil world',\n",
       " 430939: 'version depict evil world good',\n",
       " 101792: 'depict evil world good time',\n",
       " 132300: 'evil world good time decide',\n",
       " 455589: 'world good time decide make',\n",
       " 175595: 'good time decide make classic',\n",
       " 414881: 'time decide make classic timeless',\n",
       " 99487: 'decide make classic timeless story',\n",
       " 253861: 'make classic timeless story highlight',\n",
       " 80505: 'classic timeless story highlight positive',\n",
       " 416770: 'timeless story highlight positive low',\n",
       " 393660: 'story highlight positive low negative',\n",
       " 190979: 'highlight positive low negative enough',\n",
       " 328715: 'positive low negative enough negative',\n",
       " 249976: 'low negative enough negative real',\n",
       " 278038: 'negative enough negative real world',\n",
       " 72838: 'charm',\n",
       " 50371: 'billy',\n",
       " 118621: 'eichner',\n",
       " 390496: 'steal',\n",
       " 127795: 'entertain charm',\n",
       " 73169: 'charm original',\n",
       " 305874: 'original billy',\n",
       " 50376: 'billy eichner',\n",
       " 118696: 'eichner steal',\n",
       " 127796: 'entertain charm original',\n",
       " 73170: 'charm original billy',\n",
       " 305875: 'original billy eichner',\n",
       " 50416: 'billy eichner steal',\n",
       " 127797: 'entertain charm original billy',\n",
       " 73171: 'charm original billy eichner',\n",
       " 305876: 'original billy eichner steal',\n",
       " 127798: 'entertain charm original billy eichner',\n",
       " 73172: 'charm original billy eichner steal',\n",
       " 17847: 'aladdin',\n",
       " 229564: 'like like',\n",
       " 231620: 'like story',\n",
       " 392377: 'story aladdin',\n",
       " 19462: 'aladdin think',\n",
       " 411403: 'think good',\n",
       " 229592: 'like like story',\n",
       " 231621: 'like story aladdin',\n",
       " 392396: 'story aladdin think',\n",
       " 19466: 'aladdin think good',\n",
       " 229593: 'like like story aladdin',\n",
       " 231622: 'like story aladdin think',\n",
       " 392397: 'story aladdin think good',\n",
       " 229594: 'like like story aladdin think',\n",
       " 231623: 'like story aladdin think good',\n",
       " 133299: 'excellent',\n",
       " 444301: 'way',\n",
       " 29837: 'another',\n",
       " 235426: 'little',\n",
       " 328973: 'possibly',\n",
       " 316924: 'pay',\n",
       " 352197: 'retread',\n",
       " 239583: 'logical',\n",
       " 87057: 'comprehension',\n",
       " 106481: 'director',\n",
       " 213474: 'kenneth',\n",
       " 55628: 'branagh',\n",
       " 76778: 'cinderella',\n",
       " 191447: 'hint',\n",
       " 260362: 'matt',\n",
       " 205106: 'involvement',\n",
       " 367486: 'seriously',\n",
       " 428703: 'uphold',\n",
       " 141266: 'faith',\n",
       " 192891: 'honest',\n",
       " 116559: 'earnest',\n",
       " 402531: 'sweet',\n",
       " 358902: 'saccharine',\n",
       " 189136: 'heartfelt',\n",
       " 90014: 'corny',\n",
       " 86931: 'compliment',\n",
       " 204994: 'involve',\n",
       " 439290: 'wallet',\n",
       " 155027: 'fleece',\n",
       " 124684: 'engage',\n",
       " 108164: 'disney',\n",
       " 17591: 'aim',\n",
       " 190604: 'high',\n",
       " 237284: 'live',\n",
       " 7909: 'action',\n",
       " 198258: 'imaginings',\n",
       " 276893: 'necessary',\n",
       " 344706: 'refresh',\n",
       " 336873: 'quality',\n",
       " 449734: 'whilst',\n",
       " 278428: 'never',\n",
       " 148090: 'feel',\n",
       " 11736: 'actuality',\n",
       " 232580: 'lily',\n",
       " 114271: 'downton',\n",
       " 3942: 'abbey',\n",
       " 388862: 'star',\n",
       " 417466: 'titular',\n",
       " 11741: 'actually',\n",
       " 276092: 'natural',\n",
       " 52340: 'blonde',\n",
       " 266416: 'mistake',\n",
       " 204721: 'introduce',\n",
       " 119662: 'ella',\n",
       " 315752: 'parent',\n",
       " 47777: 'ben',\n",
       " 69500: 'chaplin',\n",
       " 187876: 'hayley',\n",
       " 34252: 'atwell',\n",
       " 338467: 'raise',\n",
       " 176402: 'gorgeous',\n",
       " 90989: 'country',\n",
       " 90774: 'cottage',\n",
       " 203353: 'instill',\n",
       " 98762: 'deal',\n",
       " 216078: 'kindness',\n",
       " 138730: 'exude',\n",
       " 424891: 'type',\n",
       " 176870: 'grace',\n",
       " 44382: 'beauty',\n",
       " 424250: 'tutelage',\n",
       " 140866: 'fairy',\n",
       " 403175: 'tale',\n",
       " 45220: 'begin',\n",
       " 37182: 'awry',\n",
       " 242376: 'lose',\n",
       " 269031: 'mother',\n",
       " 98908: 'death',\n",
       " 74143: 'child',\n",
       " 145795: 'father',\n",
       " 239734: 'lonely',\n",
       " 183561: 'grow',\n",
       " 105491: 'difficult',\n",
       " 75789: 'choice',\n",
       " 269637: 'move',\n",
       " 258835: 'marry',\n",
       " 107744: 'discover',\n",
       " 450195: 'widow',\n",
       " 65349: 'cate',\n",
       " 51714: 'blanchett',\n",
       " 97419: 'daughter',\n",
       " 384034: 'sophie',\n",
       " 261270: 'mcshera',\n",
       " 192330: 'holliday',\n",
       " 176966: 'grainger',\n",
       " 408013: 'the',\n",
       " 142224: 'family',\n",
       " 333608: 'problem',\n",
       " 391040: 'stepmother',\n",
       " 94198: 'cruel',\n",
       " 269350: 'motivation',\n",
       " 104798: 'different',\n",
       " 6181: 'accustom',\n",
       " 400940: 'sure',\n",
       " 387632: 'spoil',\n",
       " 55919: 'brat',\n",
       " 420473: 'treat',\n",
       " 367602: 'servant',\n",
       " 375161: 'sister',\n",
       " 298792: 'off',\n",
       " 183455: 'ground',\n",
       " 450128: 'wicked',\n",
       " 165791: 'give',\n",
       " 433704: 'villain',\n",
       " 421246: 'true',\n",
       " 342719: 'reason',\n",
       " 402778: 'sympathize',\n",
       " 426221: 'understand',\n",
       " 202162: 'inherently',\n",
       " 304679: 'opposite',\n",
       " 136733: 'experience',\n",
       " 276255: 'naturally',\n",
       " 208046: 'jealous',\n",
       " 459797: 'youth',\n",
       " 304729: 'optimism',\n",
       " 296535: 'nothing',\n",
       " 91413: 'courageous',\n",
       " 384188: 'sort',\n",
       " 204370: 'interplay',\n",
       " 114702: 'draw',\n",
       " 80661: 'classically',\n",
       " 419874: 'train',\n",
       " 334406: 'professional',\n",
       " 334568: 'project',\n",
       " 369123: 'shakespearean',\n",
       " 24338: 'angle',\n",
       " 114895: 'dream',\n",
       " 428051: 'unrealized',\n",
       " 116140: 'dynamic',\n",
       " 157652: 'fracture',\n",
       " 86871: 'complex',\n",
       " 203930: 'interest',\n",
       " 189638: 'help',\n",
       " 370733: 'short',\n",
       " 86480: 'completely',\n",
       " 140722: 'fair',\n",
       " 94072: 'crow',\n",
       " 6011: 'accomplish',\n",
       " 47406: 'belong',\n",
       " 414157: 'tier',\n",
       " 321165: 'period',\n",
       " 114494: 'drama',\n",
       " 357264: 'romance',\n",
       " 332035: 'pride',\n",
       " 330369: 'prejudice',\n",
       " 206872: 'jane',\n",
       " 139208: 'eyre',\n",
       " 367729: 'set',\n",
       " 102458: 'design',\n",
       " 56648: 'brilliant',\n",
       " 363489: 'score',\n",
       " 345111: 'regular',\n",
       " 316833: 'patrick',\n",
       " 114320: 'doyle',\n",
       " 418487: 'top',\n",
       " 296296: 'notch',\n",
       " 412907: 'thirty',\n",
       " 257381: 'male',\n",
       " 433346: 'viewer',\n",
       " 84641: 'comfortable',\n",
       " 285019: 'normally',\n",
       " 350884: 'reserve',\n",
       " 162629: 'gender',\n",
       " 326759: 'point',\n",
       " 311445: 'other',\n",
       " 352545: 'review',\n",
       " 335319: 'proverbial',\n",
       " 153460: 'finger',\n",
       " 438584: 'wag',\n",
       " 366179: 'seemingly',\n",
       " 37612: 'backwards',\n",
       " 428833: 'urgent',\n",
       " 338117: 'race',\n",
       " 275804: 'narrative',\n",
       " 129582: 'equality',\n",
       " 159017: 'frozen',\n",
       " 30972: 'apparently',\n",
       " 155758: 'follow',\n",
       " 452654: 'woman',\n",
       " 201429: 'independent',\n",
       " 332210: 'prince',\n",
       " 45909: 'believe',\n",
       " 176224: 'goofy',\n",
       " 353641: 'richard',\n",
       " 250955: 'madden',\n",
       " 161656: 'game',\n",
       " 413747: 'thrones',\n",
       " 123006: 'enchant',\n",
       " 336611: 'pursue',\n",
       " 351132: 'respectful',\n",
       " 58873: 'buffoon',\n",
       " 330650: 'presence',\n",
       " 420150: 'translate',\n",
       " 398859: 'subservient',\n",
       " 102826: 'desperate',\n",
       " 92197: 'create',\n",
       " 320174: 'performance',\n",
       " 20394: 'allow',\n",
       " 144692: 'fantastical',\n",
       " 87749: 'confidence',\n",
       " 341579: 'realistic',\n",
       " 145591: 'fashion',\n",
       " 457271: 'wrong',\n",
       " 369180: 'shame',\n",
       " 93266: 'critic',\n",
       " 422758: 'try',\n",
       " 105607: 'dig',\n",
       " 372776: 'simply',\n",
       " 31347: 'applaud',\n",
       " 118399: 'effort',\n",
       " 335040: 'proud',\n",
       " 372642: 'simple',\n",
       " 62702: 'cash',\n",
       " 176765: 'grab',\n",
       " 342471: 'realize',\n",
       " 260537: 'mature',\n",
       " 232440: 'likely',\n",
       " 198045: 'imagine',\n",
       " 388707: 'standard',\n",
       " 260692: 'maybe',\n",
       " 133898: 'excellent tell',\n",
       " 406455: 'tell make',\n",
       " 255425: 'make love',\n",
       " 248193: 'love way',\n",
       " 444378: 'way another',\n",
       " 30085: 'another little',\n",
       " 237105: 'little time',\n",
       " 415995: 'time possibly',\n",
       " 328992: 'possibly excite',\n",
       " 134613: 'excite decide',\n",
       " 99512: 'decide pay',\n",
       " 317075: 'pay retread',\n",
       " 352199: 'retread logical',\n",
       " 239588: 'logical comprehension',\n",
       " 87058: 'comprehension trailer',\n",
       " 419710: 'trailer director',\n",
       " 106685: 'director kenneth',\n",
       " 213479: 'kenneth branagh',\n",
       " 55777: 'branagh new',\n",
       " 430756: 'version cinderella',\n",
       " 77116: 'cinderella hint',\n",
       " 191464: 'hint matt',\n",
       " ...}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
